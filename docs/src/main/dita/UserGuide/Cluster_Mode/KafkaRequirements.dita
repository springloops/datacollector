<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA General Task//EN" "generalTask.dtd">
<task id="task_gmd_msw_yr">
    <title>Kafka Requirements</title>
    <taskbody>
        <context>
            <p><indexterm>cluster mode<indexterm>configuration for
                Kafka</indexterm></indexterm>Cluster mode pipelines that read from a Kafka cluster
                have the following minimum requirements: <table frame="all" rowsep="1" colsep="1"
                    id="table_agw_5pn_zw">
                    <tgroup cols="2">
                        <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                        <colspec colname="c2" colnum="2" colwidth="3.0*"/>
                        <thead>
                            <row>
                                <entry>Component</entry>
                                <entry>Minimum Requirement</entry>
                            </row>
                        </thead>
                        <tbody>
                            <row>
                                <entry>Spark Streaming</entry>
                                <entry>Spark version 1.3 through 1.6</entry>
                            </row>
                            <row>
                                <entry>Apache Kafka</entry>
                                <entry>Spark Streaming on YARN requires a Cloudera or Hortonworks
                                    distribution of an Apache Kafka cluster. <p>Spark Streaming on
                                        Mesos requires Apache Kafka on Apache Mesos.</p></entry>
                            </row>
                        </tbody>
                    </tgroup>
                </table></p>
            <p>Complete the following steps to configure a cluster mode pipeline to read from a
                Kafka cluster:<ol id="ol_e32_llw_yr">
                    <li>Verify the installation of Kafka, Spark Streaming, and either YARN or Mesos
                        as the cluster manager.</li>
                    <li>Install the <ph
                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                        /> on a Spark and YARN or a Spark and Mesos gateway node.</li>
                    <li>If necessary, specify the location of the spark-submit script. <p>The <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            /> assumes that the spark-submit script used to submit job requests to
                            Spark Streaming, is located in the following directory:
                            <codeblock>/usr/bin/spark-submit</codeblock></p>If the script is not in
                        this directory, use the following environment variables to define the
                        location of the script:<ul id="ul_xzc_bqj_f5">
                            <li>On YARN, use the SPARK_SUBMIT_YARN_COMMAND environment
                                variable.</li>
                            <li>On Mesos, use the SPARK_SUBMIT_MESOS_COMMAND environment
                                variable.</li>
                        </ul></li>
                    <li>In the pipeline properties, on the <wintitle>General</wintitle> tab, set the
                            <uicontrol>Execution Mode</uicontrol> property to <uicontrol>Cluster
                            YARN Streaming</uicontrol> or <uicontrol>Cluster Mesos
                            Streaming</uicontrol>.</li>
                    <li>On the <uicontrol>Cluster</uicontrol> tab, enter the required properties for
                        YARN or Mesos. </li>
                    <li>In the pipeline, use a Kafka Consumer origin for cluster mode. <p>If
                            necessary, select a cluster mode stage library on the
                                <wintitle>General</wintitle> tab of the origin. </p></li>
                </ol><note>When you add a partition to the Kafka topic, restart the pipeline to
                    enable the <ph
                        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> to generate a new worker to read from the new partition. </note></p>
        </context>
    </taskbody>
    <related-links>
        <link href="../Pipeline_Configuration/ConfiguringAPipeline.dita#task_xlv_jdw_kq" type="topic"/>
        <link href="../Origins/KConsumer.dita#concept_msz_wnr_5q" type="topic"/>
    </related-links>
</task>
